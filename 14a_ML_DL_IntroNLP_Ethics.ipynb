{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a97c93d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fundamental Concepts in Data Insight: \n",
    "## <font color=indigo> Natural Language Processing &amp; Ethics </font>\n",
    "\n",
    "### Fundamentals for a General Audience\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20e466a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "QA Ltd. owns the copyright and other intellectual property rights of this material and asserts its moral rights as the author. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71dd589",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### **Natural Language Processing &amp; Ethics**\n",
    "* How are words represented to machines?\n",
    "    * WB. How do you compare words?\n",
    "* How do machines process Dostoevsky?\n",
    "    * Let's get Crime and Punishment\n",
    "    * Let's model a vocabulary \n",
    "    * Let's find out how Dostoevsky uses words\n",
    "    * Does the distributional hypothesis work?\n",
    "* Natural Languages\n",
    "    * What do words mean?\n",
    "    * Can we learn word meanings by parsing text?\n",
    "    * What can we learn from text?\n",
    "    * What is association?\n",
    "    * Are Human Implicit Associations expressed in Text?\n",
    "    * Is association part of semantics?\n",
    "* Bias\n",
    "    * What is Bias?\n",
    "    * WB. How do associations relate to prejudice?\n",
    "    * Review: How do associations relate to prejudice?\n",
    "    * Can machines detect stereotypes?\n",
    "    * Where does AI bias come from?\n",
    "    * Is AI racist just because we are?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bebf263",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This module will introduce Natural Language Processing to illustrate several conceptual issues within Machine Learning. \n",
    "\n",
    "We are interested in the following questions,\n",
    "\n",
    "1. How is meaningful information encoded for digital processing?\n",
    "2. How is this encoding processed by inferential algorithms?\n",
    "3. On what basis do these algorithms plan actions?\n",
    "4. What information is omitted, or poorly represented, in this process?\n",
    "5. What ethical issues arise from the use of inferential algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0273241c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942a9cd4",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Aside: Module Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d26ce4c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "You may need to install a library to run code in this module,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8133f52",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q gensim python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0441e985",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/michael/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk; nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95fea490",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd21384",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1672a269",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How are words represented to machines?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc287c6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Consider the sentence, \"the cat sat on the mat\".\n",
    "\n",
    "In order to draw automated inferences from this sentence (eg., \"the mat has a cat sat on it\"), we need to represent it for a digital computer.\n",
    "\n",
    "That is, our goal is to *encode* this setence as a sequence of numbers for digital processing.\n",
    "\n",
    "Let's assign a random number to each term,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e25fe869",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from random import randint; random_number = lambda: randint(0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2790da2f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1, 'cat': 0, 'sat': 4, 'on': 3, 'mat': 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = \"the cat sat on the mat\".split()\n",
    "\n",
    "words = { word: random_number() for word in phrase }\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da48619",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These numbers arent unique, so we wouldn't be able to use them as-is. A computer could not distinguish, say, 'cat' from 'sat'. \n",
    "\n",
    "How should we update them? What is the *best* choice of number for each word?\n",
    "\n",
    "Is there a way we can capture the *meaning* of a word numerically?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb00cfa0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consider trying to make the number choice represent how *related* the words are. \n",
    "\n",
    "Eg., 'the' is two words *before* 'sat'.\n",
    "\n",
    "To do this we will record a set of numbers for each word, their *relative position* to other words,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feda8f2a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "words = { word: { word: 0 for word in phrase } for word in phrase }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d42a9c68",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': {'the': 0, 'cat': 0, 'sat': 0, 'on': 0, 'mat': 0},\n",
       " 'cat': {'the': 0, 'cat': 0, 'sat': 0, 'on': 0, 'mat': 0},\n",
       " 'sat': {'the': 0, 'cat': 0, 'sat': 0, 'on': 0, 'mat': 0},\n",
       " 'on': {'the': 0, 'cat': 0, 'sat': 0, 'on': 0, 'mat': 0},\n",
       " 'mat': {'the': 0, 'cat': 0, 'sat': 0, 'on': 0, 'mat': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46c217",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since `sat` is two before `the`, we can update manually,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e8c5514",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "words['the']['sat'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31df93c4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': {'the': 0, 'cat': 0, 'sat': 2, 'on': 0, 'mat': 0},\n",
       " 'cat': {'the': 0, 'cat': 0, 'sat': 0, 'on': 0, 'mat': 0},\n",
       " 'sat': {'the': 0, 'cat': 0, 'sat': 0, 'on': 0, 'mat': 0},\n",
       " 'on': {'the': 0, 'cat': 0, 'sat': 0, 'on': 0, 'mat': 0},\n",
       " 'mat': {'the': 0, 'cat': 0, 'sat': 0, 'on': 0, 'mat': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8e5c80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we fill this table out, we know how each word is related (*by position*) to the other terms,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f749695",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "relations = pd.DataFrame({ word: { \n",
    "    related:  abs(phrase.index(word) - phrase.index(related)) \n",
    "      for related in words \n",
    "    } for word in phrase \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b42f060",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>cat</th>\n",
       "      <th>sat</th>\n",
       "      <th>on</th>\n",
       "      <th>mat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mat</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     the  cat  sat  on  mat\n",
       "the    0    1    2   3    5\n",
       "cat    1    0    1   2    4\n",
       "sat    2    1    0   1    3\n",
       "on     3    2    1   0    2\n",
       "mat    5    4    3   2    0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5c8a0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This table provides a means of encoding each word. \n",
    "\n",
    "However the encoding is *relative* to a body of text (ie., the numbers will be different, given a different phrase). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edbe289",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The \"Distributional Hypothesis\" says the *relative position* of terms is a *guide to their meaning*.\n",
    "\n",
    "> linguistic items with similar distributions have similar meanings -- wikipedia, Distributional Semantics\n",
    "\n",
    "Read literally, this seems false: *that* we happen to write words together does not imply they mean the same thing.\n",
    "\n",
    "This hypothesis has lead to the view that the best way of capturing the *meaning* of a word is to analyse its frequency and position as it occurs *in a vast library of documents*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d08e687",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## WB. How do you compare words?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14949fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## WB. How do you compare words?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe55cfa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do machines process Dostoevsky?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b0eeb3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Let's get Crime and Punishment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8facf6c4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Downloading the \"Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ed67262",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "book = request.urlopen(\"http://www.gutenberg.org/files/2554/2554-0.txt\").read().decode('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177c4f0c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And for later processing, we need the book formatted into its sentences,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "581f1317",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb4825a0",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences in book: 12059\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences in book:\", len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f461d8ec",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The 101st sentence is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad4f55c1",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bell gave a faint tinkle as though it were made of\r\n",
      "tin and not of copper.\n"
     ]
    }
   ],
   "source": [
    "print(*sentences[101:102])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13506c18",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042d07b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's model a vocabulary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f273f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The process we performed manually above, *encoding* text, can be done automatically. There are many approaches here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e75a19",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The `Word2Vec` algorithm scans the sentences of the book looking at how often words occur togther. \n",
    "\n",
    "It *reexpresses* a word as a series of (eg.,) 100 numbers. \n",
    "\n",
    "If we expressed a word in terms of how it related to *all possible other words*, each would be $400,000$ numbers or more. Consider the question, \"how often is brick near wall?\" but for every possible pair of words. \n",
    "\n",
    "The $100$-number version is an attempt at a compressed verison of this much longer set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff90eba4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can build a \"vocabulary\" of these 100-number \"words\", automatically, from \"Crime and Punishment\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13959422",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sentence_words = [ line.split() for line in sentences ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddac4228",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vocab = Word2Vec(sentence_words).wv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1c267a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The word `man` corresponds to the following numbers,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68ebada8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05,  0.54,  0.34,  0.21,  0.23, -0.66,  0.4 ,  0.62, -0.21,\n",
       "       -0.39, -0.06, -0.31,  0.23,  0.24,  0.06, -0.17,  0.37, -0.48,\n",
       "       -0.1 , -1.1 ,  0.29, -0.05,  0.65, -0.04, -0.3 ,  0.16,  0.06,\n",
       "       -0.15, -0.28,  0.18,  0.46, -0.42,  0.58, -0.48, -0.09,  0.31,\n",
       "       -0.05, -0.14, -0.17, -0.61,  0.39, -0.42, -0.21,  0.21,  0.07,\n",
       "        0.22, -0.36, -0.13,  0.08,  0.39,  0.03, -0.34, -0.03, -0.34,\n",
       "       -0.24,  0.23, -0.15, -0.13, -0.49,  0.09, -0.04, -0.18,  0.02,\n",
       "        0.18, -0.03,  0.57,  0.1 ,  0.48, -0.39,  0.22, -0.12,  0.18,\n",
       "        0.32,  0.16,  0.42,  0.06,  0.1 , -0.07, -0.06, -0.17, -0.63,\n",
       "        0.05, -0.47,  0.26, -0.4 , -0.5 ,  0.5 ,  0.29,  0.13, -0.29,\n",
       "        0.39, -0.26,  0.06,  0.11,  0.2 ,  0.  ,  0.22, -0.26, -0.1 ,\n",
       "       -0.11], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['man'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e68ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's find out how Dostoevsky uses words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13f3e309",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm as length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3644af90",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A simple mathematical operation (multiplying all numbers and totalling the result) is here taken as a guide to how similar two words are.\n",
    "\n",
    "Consider the 100-numbers for `child` and 100-numbers for `man`, `child @ man` means multipling each number in-turn and summing the result,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0966b72a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9714216, 0.88394564, 0.9478421, 0.95429015)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child   = vocab['child']  / length(vocab['child'])\n",
    "man     = vocab['man']    / length(vocab['man'])\n",
    "weak    = vocab['weak']   / length(vocab['weak'])\n",
    "strong  = vocab['strong']   / length(vocab['strong'])\n",
    "\n",
    "child @ man, man @ weak, man @ strong, child @ weak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b543ad6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Each number above is a guide to how similar the words are, essentially derived from *how often they occur near each other*. \n",
    "\n",
    "<small>Aside: the `vocab['man'] / length(vocab['man'])` operation is needed to place all the numbers on the same scale, so they can be compared. </small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eda2d344",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('by', 0.9796208143234253),\n",
       " ('little', 0.9786400198936462),\n",
       " ('who', 0.9785995483398438),\n",
       " ('wood', 0.9781473278999329),\n",
       " ('expression', 0.9781315922737122),\n",
       " ('fever', 0.9776231646537781),\n",
       " ('time', 0.9774249196052551),\n",
       " ('full', 0.977258026599884),\n",
       " ('woman', 0.977125346660614),\n",
       " ('other', 0.9770156145095825)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6487e45a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('new', 0.9991231560707092),\n",
       " ('A', 0.9988678693771362),\n",
       " ('drunken', 0.9988556504249573),\n",
       " ('later', 0.9986962676048279),\n",
       " ('between', 0.998674750328064),\n",
       " ('young', 0.9986497759819031),\n",
       " ('letter', 0.9986132979393005),\n",
       " ('cold', 0.9985955953598022),\n",
       " ('second', 0.9985937476158142),\n",
       " ('idea', 0.9985917806625366)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.most_similar('girl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e195d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Does the distributional hypothesis work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9279f516",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The claim of adhearents is that *with enough text* we are sure to capture what words mean. \n",
    "\n",
    "There are major problems with this idea, not least that (1) the scale of text needed  runs into trillions of examples; and (2) no matter how texts *contain* words their meaning is determined by *use*.\n",
    "\n",
    "The latter is a *fatal* problem: the co-occurance of words in some text **isn't** what they *mean*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d18ff2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Natural Languages\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461809c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What do words mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c8d40e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Meaning is use -- Wittigenstein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ecac78",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Words are like *tools* (eg., a hammer). Their meaning is how we *use them like tools*. \n",
    "\n",
    "Eg., two people are talking, one says \"pass me the salt\" and the other hands them the salt. \n",
    "\n",
    "The *tool* \"salt\" comes to *refer to* **the salt in our shared environment** in the context of this communication. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a826e70",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The communicative actions between the two speakers is *primary*. \n",
    "\n",
    "We are *first* acting within shared enviroments, and second, we use words to *help us do this*. \n",
    "\n",
    "Aside: it is not clear if \"salt\" has any meaning outside of a communicative context; or if it does, this very general sort of meaning is merely *the many potential specific **uses** it could acquire*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1386a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Can we learn word meanings by parsing text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af1341d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since machines do not use words (as above, like tools), they do not *mean* anything when they generate text.\n",
    "\n",
    "Consider a machine generating the text \"pass me the salt\" here it cannot mean what *I* say when *I* say, \"pass me the salt\": I want the salt. The machine isn't even aware of salt, nor has ever encountered any (etc.).\n",
    "\n",
    "Since the machine isn't *with me*, it isnt *talking to me*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d878889f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Suppose I input, \"I like salt on chips\" and it replies, \"I like vinegar, try vinegar too!\". Approximately, it replies *because* vinegar *is associated with salt*, and that *try .. too!* is associated with *like*. \n",
    "\n",
    "What's missing here is that the machine has never tried vinegar, has no knoweldge *of vinegar*, and only knowledge of *the term vinegar*: ie., what other terms co-occur in historical texts. \n",
    "\n",
    "So it cannot possibly *use* the phrase \"I like vinegar\". And if it not *using* it, it is not *meaning* it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fa1a05",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Aside: consider also a non-english speaker being instructed to say \"Eye LieKuh Vee Nee Guar\", do they? Do those *sounds* **mean** anything? Consider a cave through which a wind blows similar sounds: is it speaking?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fbba3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What can we learn from text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585bdb20",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can determine *statistical term associations* from text, eg., that \"King\" is associated with \"Queen\". \n",
    "\n",
    "Since statistical AI can only parse text, it is *asserted* that meaning *is* asssocation (distributional hypothesis). \n",
    "\n",
    "However we need to be extremely warey of this claim. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944d0bc1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is association?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ac7b7a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Association is how likely it is two *terms* are *related*. A statistical association is evidencing that association by co-occurance in some body of text. \n",
    "\n",
    "For example, I might *associate* \"candy\" with \"horror\" if I only eat sweets when watching horror films. A statistical anaysis of my chat history *might* capture this; it might not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb0da65",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can define statistical association as a probability.\n",
    "\n",
    "Two terms are associated if, in any sequence of words,\n",
    "\n",
    "* $P(Current Term = A | Previous = B) > P(Current Term = A)$\n",
    "* $P(Term = King| Previous = Queen) > P(King | Previous=Anything)$\n",
    "\n",
    "\n",
    "* Generically, \n",
    "* for a set of options $O_1, O_2, \\dots$,\n",
    "    * $P(A|O_1) > P(A|O_1)$ says $O_1$ is more associated with $A$ than $O_2$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598e3570",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Human Implicit Associations are expressed in Text Associations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5789389",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "An *implicit association* is any association we make which isn't explicitly expressed in our understanding of what we believe about a topic or ourselves.\n",
    "\n",
    "> The implicit-association test (IAT) is a controversial assessment in the field of social psychology intended to detect the strength of a person's subconscious association between mental representations of objects (concepts) in memory. It is commonly applied to assess implicit stereotypes held by test subjects, such as unconsciously associating stereotypically black names with words consistent with black stereotypes.[1] The test's format is highly versatile, and has been used to investigate biases in racial groups, gender, sexuality, age, and religion, as well as assessing self-esteem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38507338",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Eg., $P(\\text{Person is Powerful} | Male) > P(\\text{Person is Powerful} | Female)$\n",
    "\n",
    "The IAT test is, roughly, a system which measures how quickly we respond to words being shown on screen with each other. The central claim of this test is that systematic timing differences reveal associations. \n",
    "\n",
    "Whether this is true or not, it is not in doubt that people associate terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d302a2ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Is association part of semantics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e61af3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Some$^1$ natural language processing adhearents believe the distributional hypothesis, and *in addition*, a hypothesis about association,\n",
    "\n",
    "1. The meaning of a term is the terms it's associated with\n",
    "2. *Association* is statistical association\n",
    "3. Statistical association can be determined by scanning a representative amount of text\n",
    "\n",
    "($^1$ It tends not to be the most senior practicioners in the area, but junior practicioners or people *selling* the technology.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af06693",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are major problems with this. \n",
    "\n",
    "**One**\n",
    ": that *how* we associate ideas is not expressed in the way the terms are distributed in text. We may believe \"X\" and \"Y\" are connected by *similarity*; and \"A\" and \"B\" by *cultural contingency* but the cooccurance of X-Y and A-B may be identical.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b9b327",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Two**: If we claim that *association is meaning* then we build incidental stereotypes into the meaning of words themselves.\n",
    "\n",
    "People associate terms of all kinds of private incidental reasons and are aware that these associations do not bare on the meaning of the term (\"candy\" does not mean \"horror\"). Worse statistical term assocaitions do not capture even *our* associations.\n",
    "\n",
    "If association is meaning then it is *literally* the case that \"Programmer\" means \"a man who...\". As many associate \"Programmer\" with \"Man\", and even if these associations change **much historical text** continues to do so!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0f39df",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Programmer is a well-defined term which can be used to *communicate successfully* in many contexts where both women and men are being considered. \n",
    "\n",
    "Note that it is because *meaning isn't association*, we are able to correct and identify misunderstanding.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b776a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59576c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f644d25",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since NLP systems work on statistical associations (as, essentially does every ML technique), we are in great danger of encoding non-semantic sterotypical assumptions into algorithmic decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882cb8a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Bias?\n",
    "* statistical bias\n",
    "    * systematic inaccuracy\n",
    "* biased decision/treatment\n",
    "    * unfair treatment\n",
    "* subjective bias\n",
    "    * stake in the outcome\n",
    "* biased process\n",
    "    * process with unfair concequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b96d69",
   "metadata": {},
   "source": [
    "## WB. How do associations relate to prejudice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d2cd40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review: How do associations relate to prejudice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e230bee4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* prior associations, \n",
    "    * expectations derived from experience *of* regularities\n",
    "    * eg., $P(\\text{Programmer is Male}) > P(\\text{Programmer is Female})$\n",
    "    * thef. \"Programmer\" is associated with \"Male\"\n",
    "* stereotype\n",
    "    * we believe something **normative** *about* an association (which are circumstantial/cultural)\n",
    "        * eg., \"Popular = Good\"\n",
    "        * eg., \"Common = Safe, Normal, ...\"\n",
    "    * so we take the more associated option as being *good* \n",
    "        * a sterotype is a immoral conclusion of this kind\n",
    "        * an archetype is a morally neutral example\n",
    "    * eg., \"Since programmers are mostly male, being male is characteristic of being a good programmer\"\n",
    "* prejudical action\n",
    "    * making decisions based on sterotypes\n",
    "    * eg., \"Since programmers are mostly male, being male is characteristic of being a good programmer\"\n",
    "        * **therefore** hiring only *male* programmers\n",
    "\n",
    "\n",
    "A *prior association* is evidence for beliefs about the types of things being associated. It is an ethical problem when we form *normative* beliefs which lead to prejudicial actions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb614a61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Can machines detect stereotypes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf3ee3e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "No.\n",
    "\n",
    "* Machnines have no access to natural word semantics, ie., meaning \n",
    "    * they can only observe association\n",
    "\n",
    "* $P(Prg = Male|Text) > P(Prg = Female|Text)$ **is true** \n",
    "    * the machine cannot distinguish this from $P(Bee = Insect|Text) > P(Bee = Fish|Text)$\n",
    "    \n",
    "* NLP systems only have access to this information, so they learn both:\n",
    "    * Bees are insects\n",
    "    * Programmers are male"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c8c85b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Where does AI bias come from?\n",
    "\n",
    "\n",
    "* inherent to algorithm\n",
    "    * misattributing association for meaning\n",
    "* human labelling (via culture)\n",
    "* system design (ignorance of developer)\n",
    "* delibate (intention of developer)\n",
    "* and more..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72e1bbc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Is AI racist just because we are?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8204a2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Consider processing a book of policy which advocates for improving the circumstances of a minority. The machine will likely *statistically associate* ethnic terms with *negative words* precisley because the book is *about* that association. However the book is a *refutation* of this association, not an endorsement. \n",
    "\n",
    "The issue here isn't the racism of the authors, or the malice or racism of the culture. The issue is that the distributional hypothesis is false. The machine has no access to the meaning of what's said, so it reporduces racism *where none existed*. \n",
    "\n",
    "This isn't \"machines reporducing the bias and racism of culture\". It is machines creating *novel racism* where none existed prior. \n",
    "\n",
    "It is often claimed by proponents of this technology that the problem is \"in people\", and the machines are merely passive observes of the truth of *what we mean when we talk to one another*. However this must be wholey rejected if we are to anticipate all the ethical concequences of these systems. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
